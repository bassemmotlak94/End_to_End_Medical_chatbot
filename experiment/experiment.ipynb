{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.embeddings import HuggingFaceBgeEmbeddings\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.prompts import PromptTemplate\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data):\n",
    " loader = DirectoryLoader(data,\n",
    "                          glob=\"*.pdf\",\n",
    "                          loader_cls=PyPDFLoader\n",
    "\n",
    " )\n",
    " documents = loader.load()\n",
    " return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_data = load_data(\"../Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'producer': 'PDFlib+PDI 5.0.0 (SunOS)', 'creator': 'PyPDF', 'creationdate': '2004-12-18T17:00:02-05:00', 'moddate': '2004-12-18T16:15:31-06:00', 'source': '..\\\\Data\\\\Medical_book.pdf', 'total_pages': 637, 'page': 0, 'page_label': '1'}, page_content='')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_split(extracted_data):\n",
    " text_splitter = RecursiveCharacterTextSplitter(chunk_size = 500,chunk_overlap=20)\n",
    " text_chunks= text_splitter.split_documents(extracted_data)\n",
    " return text_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_chunks = text_split(extracted_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5860"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceBgeEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_HuggingFaceEmbeddings():\n",
    "  embiddings =HuggingFaceBgeEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "  return embiddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\Anaconda_app\\envs\\mchatbot\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    }
   ],
   "source": [
    "embiddings = download_HuggingFaceEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HuggingFaceBgeEmbeddings(client=SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False}) with Transformer model: BertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       "  (2): Normalize()\n",
       "), model_name='sentence-transformers/all-MiniLM-L6-v2', cache_folder=None, model_kwargs={}, encode_kwargs={}, query_instruction='Represent this question for searching relevant passages: ', embed_instruction='', show_progress=False)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embiddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "embidding = embiddings.embed_query(\"Hello world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embidding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_key = os.getenv(\"PINECONE_API_KEY\")\n",
    "index_name = \"testing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = PineconeVectorStore.from_documents(text_chunks, embiddings, index_name=index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_3 =vector_store.similarity_search(\"What are Alergies\",k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "and the eustachian tube, hypertrophied adenoids can also\n",
      "obstruct it and cause middle ear infections.\n",
      "KEY TERMS\n",
      "Eustacian tube—A tube connecting the middle ear\n",
      "with the back of the nose, allowing air pressure to\n",
      "equalize within the ear whenever it opens, such as\n",
      "with yawning.\n",
      "Hyperplastic—Overgrown.\n",
      "Hypertrophy—Overgrowth.\n",
      "Strep throat—An infection of the throat caused by\n",
      "bacteria of the Streptococcus family, which causes\n",
      "tonsillitis.\n",
      "Ulcerated—Damaged so that the surface tissue is \n",
      " --------------------\n",
      "off the invaders. Often it does not completely return to its\n",
      "former size. Each subsequent infection leaves behind a\n",
      "larger set of tonsils and adenoids. To make matters\n",
      "worse, the sponge-like structure of these hypertrophied\n",
      "glands can produce safe havens for germs where the\n",
      "body cannot reach and eliminate them. Before antibi-\n",
      "otics and the reduction in infectious childhood diseases\n",
      "over the past few generations, tonsils and adenoids\n",
      "caused greater health problems.\n",
      "Causes and symptoms \n",
      " --------------------\n",
      "viating the cause of the problem. Acute tonsillitis also\n",
      "benefits from warm saline gargles.\n",
      "Prognosis\n",
      "Hypertrophied adenoids are a normal part of grow-\n",
      "ing up and should be respected for their important role in\n",
      "the development of immunity. Only when their size caus-\n",
      "es problems by obstructing breathing or middle ear\n",
      "drainage do they demand intervention.\n",
      "Prevention\n",
      "Prevention can be directed toward prompt evaluation\n",
      "and appropriate treatment of sore throats to prevent over- \n",
      " --------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(top_3)):print(top_3[i].page_content,\"\\n\",\"--\"*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "template=\"\"\"\n",
    "Use the following pieces of information to answer the user's question.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "\n",
    "Only return the helpful answer below and nothing else.\n",
    "Helpful answer:\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template=PromptTemplate(template=template,\n",
    "                               input_variables=[\"context\",\"question\"],\n",
    ")\n",
    "chain_type_kwargs={\"prompt\":prompt_template}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_key = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGroq(model = \"deepseek-r1-distill-llama-70b\"\n",
    "               ,api_key= groq_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = RetrievalQA.from_chain_type(llm=llm,chain_type_kwargs=chain_type_kwargs,\n",
    "           retriever = vector_store.as_retriever(search_kwargs={\"k\":3}),\n",
    "            chain_type=\"stuff\" )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, I need to answer the question \"What is acne?\" using the provided context. Let me go through each piece of information step by step.\n",
      "\n",
      "First, the context mentions that acne is the general name given to a skin disorder where the sebaceous glands become inflamed. That's a good starting point. I should explain that acne is a skin condition involving inflammation of the sebaceous glands.\n",
      "\n",
      "Looking further, there's a mention of \"Acne vulgaris\" affecting a woman’s face. I remember that Acne vulgaris is the most common form of acne, so it's important to note that it's the most common type.\n",
      "\n",
      "I also see that the context includes references to various articles and journals, but the specific details about what causes acne or its symptoms aren't provided here. I should stick to the information given without adding anything extra.\n",
      "\n",
      "So, putting it all together, the answer should be concise, stating that acne is a skin disorder characterized by inflammation of the sebaceous glands, with the most common form being Acne vulgaris, typically affecting areas like the face.\n",
      "</think>\n",
      "\n",
      "Acne is a skin disorder where the sebaceous glands become inflamed. The most common form is Acne vulgaris, often affecting the face.\n"
     ]
    }
   ],
   "source": [
    "query =\"what is acne\" \n",
    "result = qa.invoke(query)\n",
    "print(result[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mchatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
